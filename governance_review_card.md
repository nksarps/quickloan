# QuickLoan Governance Review Card

| Section | Issue/Definition | Impact | Suggested Fix/Mitigation |
|---------|-----------------|--------|-------------------------|
| 1. **Data Quality Risk** | Customer data entering the system is frequently incomplete and inconsistently formatted, with missing income fields and irregular phone number structures, resulting in unreliable inputs for the machine learning model. | Poor data quality reduces model accuracy and increases the risk of incorrect loan approvals or rejections. | Implement mandatory field validation at data entry, enforce standardized formatting rules, add automated data cleaning in preprocessing, and monitor quality through continuous data quality checks. |
| 2. **Legal & Compliance Risk** | The mobile application collects excessive personal information, including full contact lists, without obtaining explicit and informed user consent, creating a significant risk of non-compliance with Ghanaâ€™s Data Protection Act, 2012 (Act 843). | Exposure to regulatory penalties, legal action, reputational damage, and loss of customer trust. | Apply Data Minimization by limiting collection to essential loan-related data, implement explicit consent capture with audit logging, define clear processing purposes, and enforce structured data retention policies. |
| Data Classification | Sensitive | Loan application data contains financial records and personally identifiable information that require the highest level of protection. | Enforce encryption, access controls, and strict retention policies appropriate for Sensitive data. |
| 3. **Bias & Fairness Risk** | The automated loan-scoring model may produce unfair outcomes because it is trained on historical approval data that may reflect existing socio-economic or geographic inequalities. | Certain demographic groups may experience disproportionate loan denials, leading to ethical concerns and reputational risk. | Conduct periodic fairness audits, compare approval rates across demographic groups, and retrain the model using bias mitigation techniques when disparities are identified. |
| Source of Bias | Historical lending data embedded with past discriminatory patterns. | Reinforces systemic inequalities through automated decision-making. | Introduce balanced training datasets and fairness testing before deployment. |
| 4. **Storytelling/Reporting Recommendation** | Implement a transparent fairness reporting framework to monitor automated lending decisions. | Improves accountability and builds stakeholder trust. | Publish periodic fairness and compliance reports to internal leadership. |
| Metric to Monitor (name & definition) | **Demographic Approval Rate Disparity (DARD):** The percentage difference in loan approval rates between defined demographic groups within a reporting period. | Enables measurable tracking of fairness in lending decisions. | Review monthly and escalate significant disparities for investigation. |
| Visualization Type | Grouped Bar Chart | Allows easy comparison of approval rates across demographic groups. | Use in executive dashboards for clear visibility. |
| Why It Matters | Continuous monitoring of approval disparities ensures ethical AI governance and regulatory compliance. | Prevents discriminatory practices and protects company reputation. | Supports transparent and responsible fintech operations. |
